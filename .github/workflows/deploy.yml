name: Deploy DAG to GCP

on:
  push:
    branches:
      - main

jobs:
  deploy:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      id-token: write

    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Authenticate with GCP
        uses: google-github-actions/auth@v1
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - name: Set up gcloud CLI
        uses: google-github-actions/setup-gcloud@v1

      - name: Deploy DAG to Cloud Composer
        run: |
          gsutil cp dags/predict_payroll.py gs://us-east1-forecast-weekly-42c48210-bucket/dags/dags/  # Copy the DAG file
          gsutil cp src/* gs://us-east1-forecast-weekly-42c48210-bucket/dags/src/ # Copy the src folder and its content.
          gsutil cp data/train.csv gs://us-east1-forecast-weekly-42c48210-bucket/dags/data/  # Copy only sales files
          gsutil cp requirements.txt gs://us-east1-forecast-weekly-42c48210-bucket/dags/ # Copy requirements.txt to dags folder

      - name: Trigger DAG in Airflow (optional)
        run: |
          gcloud composer environments run predict-payroll \
            --location us-east1 dags trigger -- predict_payroll
